{"meta":{"title":"Jason Say","subtitle":"","description":"Jason写字的地方","author":"Jason Wang","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"每天一小时java计划01 - volatile","slug":"每天一小时java计划01 - volatile","date":"2017-08-21T00:00:00.000Z","updated":"2017-08-21T05:33:40.220Z","comments":true,"path":"2017/08/21/每天一小时java计划01 - volatile/","link":"","permalink":"http://yoursite.com/2017/08/21/每天一小时java计划01 - volatile/","excerpt":"","text":"原文链接：http://www.cnblogs.com/dolphin0520/p/3920373.html 1.volatile关键字的两层语义一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。2）禁止进行指令重排序。先看一段代码，假如线程1先执行，线程2后执行：12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125; //线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。但是用volatile修饰之后就变得不一样了：第一：使用volatile关键字会强制将修改的值立即写入主存；第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。那么线程1读取到的就是最新的正确的值。 2.volatile保证原子性吗？从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？下面看一个例子：1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：假如某个时刻变量inc的值为10，线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。那么两个线程分别进行了一次自增操作后，inc只增加了1。解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。把上面的代码改成以下任何一种都可以达到效果：采用synchronized：1234567891011121314151617181920212223public class Test &#123; public int inc = 0; public synchronized void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用Lock：1234567891011121314151617181920212223242526272829public class Test &#123; public int inc = 0; Lock lock = new ReentrantLock(); public void increase() &#123; lock.lock(); try &#123; inc++; &#125; finally&#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用AtomicInteger：1234567891011121314151617181920212223public class Test &#123; public AtomicInteger inc = new AtomicInteger(); public void increase() &#123; inc.getAndIncrement(); &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 3.volatile能保证有序性吗？在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。volatile关键字禁止指令重排序有两层意思：1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。可能上面说的比较绕，举个简单的例子：12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。那么我们回到前面举的一个例子：123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.volatile的原理和实现机制前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。下面这段话摘自《深入理解Java虚拟机》：“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；2）它会强制将对缓存的修改操作立即写入主存；3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 5.使用volatile关键字的场景synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：1）对变量的写操作不依赖于当前值2）该变量没有包含在具有其他变量的不变式中实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。下面列举几个Java中使用volatile的几个场景。1.状态标记量1234567891011121314151617181920volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125;volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); 2.double check1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 至于为何需要这么写请参考：《Java 中的双重检查（Double-Check）》http://blog.csdn.net/dl88250/article/details/5439024和http://www.iteye.com/topic/652440参考资料：","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"kubernetes和Swarm，你站哪一队？","slug":"kubernetes和Swarm，你站哪一队？","date":"2017-08-18T07:44:33.000Z","updated":"2017-08-18T08:44:10.780Z","comments":true,"path":"2017/08/18/kubernetes和Swarm，你站哪一队？/","link":"","permalink":"http://yoursite.com/2017/08/18/kubernetes和Swarm，你站哪一队？/","excerpt":"","text":"前言前几天阿里云的技术专家来我司介绍云计算相关产品，提到了关于容器编排技术的选择。由于阿里是Docker中国目前唯一代理，所以态度明确的表达大B企业应该使用dockerEE+Swarm。这也引起了我们新一轮的调研和考量（我们前期使用的是k8s）。 背景当前主流的容器集群管理技术，包括了 Docker 官方的 Docker Swarm、Twitter 背书的 Mesos 和 Google 背书的 Kubernetes。由于Apache Mesos 只是一个分布式内核，目前的发展方向是数据中心操作系统（DCOS），它同时支持 Marathon、Kubernetes 和 Swarm 等多种框架，连 Mesosphere 也是 Kubernetes 生态的一员，从编排的角度，讨论 Mesos 意义不大，故而只对比 Docker Swarm 和 Kubernetes。 我个人的立场kubernetes是更为成熟的编排工具，有google背书，社区活跃明显超过Swarm，并且考虑到目前Docker公司和整个CaaS生态圈的关系，如果非要站队，我会选择Kubernetes 分析先上一张对比图（来自网易） 可以看到，起码就目前而言，Swarm在各个方面都明显弱于K8S。首先，K8S社区活跃度要明显高于Swarm，甚至不在一个量级，社区活跃并不是说当遇到问题是仰仗社区解决问题，而是说明有更多厂商企业使用，有更多的最佳实践经验可以借鉴。 其次，核心功能上Swarm也还缺少很多，虽然swarm肯定会后续不断完善，但那显然需要时间的检验。 而swarm唯一的优势或许是集成在了Docker中，自然有利于开发者获得集群的能力，却也颠覆了系统级程序专注、松耦合的理念，新架构在生产环境中的稳定可靠，可能还需要更多的说服力。 最后，Docker本身的发展和CaaS生态圈也是摩擦重重，出现了很多的槽点，比如： Docker向后兼容性问题 Docker容器在某些生产环境运行不够稳定，在企业级方面还有待提高 越过了操作系统的界限（Docker似乎不愿使用systemd，取而代之使用Docker Daemon来提供初始化，服务激活，安全和容器日志的相关功能） 如果甚至都不用Docker呢我们很容易的想到，以Docker目前的发展态势来说，一旦docker和google等巨头闹翻，那基于k8s+docker来做的系统就没法使用了吗？ 我觉得也并不是。 首先，我们最简单的方式，或许是不升级新的docker版本，最多就是后续问题不在有docker官方支持。但我相信这么多企业在用k8s，到时候google或者其他大厂、社区必定会有相应解决方案。 而且google等厂商也已经准备了应对之策，那就是在CaaS中废弃Docker，对容器进行抽象，用谁的容器都可以。容器运行时不再用Docker，而直接采用RunC，容器扩展功能通过插件来实现，基本就是全抛弃Docker了。目前RunC是三大容器厂商共同支持的标准：CoreOS Rocket, Cloud Foundry Garden和Docker容器。 目前的形势，就形成了Docker和各个CaaS/PaaS厂商在同一层面竞争，在CaaS/PaaS平台，Docker并没有什么优势，但是Docker想把其容器的广泛使用的优势在CaaS中延续，目前看来并不容易。容器的主要用户还是个人用户、开发者用户、运维用户，而CaaS是企业系统，二者目标客户不同、技术要求不同。 随着这个生态的演进，Docker容器会更多的用于开发、测试环境，而RunC在各个CaaS厂商的推动下会在生产环境得到广泛的应用。 另外其实容器技术壁垒并不高，容器最主要的两个的技术来源：1、 Namespace—来源于IBM2、 cGroup—-来源于Google其他的容器核心技术都是Linux操作系统的功能，容器的核心技术是和Linux操作系统密切相关的，Docker本身在容器核心并没有什么贡。所以容器生态圈的公司撇开Docker做一个容器标准不是难事。 作为用户或是容器生态圈的创业公司，不能一棵树上吊死，如果在容器层面只考虑Docker，而不考虑RunC，可能会和CaaS/PaaS生态圈的标准越来越远，未来和CaaS/PaaS的标准容器差异越来越大，主流的CaaS/PaaS厂商和技术，如K8s/Mesos/Cloud Foundry均不再支持Docker容器超越RunC之外的功能，而只支持插件对RunC功能的扩展。 业界更普遍的定位是Docker用于开发测试环境，而RunC用于生产环境，所以对于要在生产环境采用容器技术的，一定要研究RunC。 总结对于企业来说，目前使用Kubernetes+Docker或许是最好的选择，而未来的方向应该是转向Kubenetes+RunC。而到时候转换的成本其实也不用担心，其实现在已经有Docker镜像转为RunC镜像的方式了（Riddler） 参考http://tech.china.com/article/20161213/201612139121.htmlhttp://www.weixinnu.com/tag/article/2817098942https://blog.c.163.com/2016/11/735/","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"java实现kubernates API的访问调用","slug":"java实现kubernates-API的访问调用","date":"2017-08-07T01:44:33.000Z","updated":"2017-08-09T02:12:47.685Z","comments":true,"path":"2017/08/07/java实现kubernates-API的访问调用/","link":"","permalink":"http://yoursite.com/2017/08/07/java实现kubernates-API的访问调用/","excerpt":"","text":"1. 前言kubernetes及各开源社区为开发人员提供了各种语言版的Client Library，让我们可以通过编程的方式可以实现调用Kubernetes API，从而完成pod、service、RC等资源的图形化创建和管理。本篇主要介绍使用java语言的实现 2. 使用场景开发基于kubernetes的容器云管理平台 3. 基于的框架用java语言开发的有两种，一个是基于Jersey的，一个是基于Fabric8。 -Jersey是一个方便简化开发RESRFul Web Service的框架，契合kubernetesAPI的设计，所以采用jersey会比较省力，但还是需要开发者自己做很多工作。 -Fabric8中的kubernates-client.xx.jar，kubernates-model.xx.jar等工具包包对kubernates api做了很好的封装，访问代码比较简单。 本篇将选择fabric8实现 4. 使用步骤4.1 首先导入核心jar包 4.2 创建连接API-Server的client123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package org.demo.framework.engine.k8s.util;import io.fabric8.kubernetes.api.model.*;import io.fabric8.kubernetes.api.model.extensions.*;import io.fabric8.kubernetes.api.model.extensions.Deployment;import io.fabric8.kubernetes.client.Config;import io.fabric8.kubernetes.client.ConfigBuilder;import io.fabric8.kubernetes.client.*;import okhttp3.TlsVersion;import org.apache.log4j.Logger;import java.io.Closeable;import java.util.ArrayList;import java.util.LinkedList;import java.util.List;import java.util.Map;public class Fabric8KubeUtils implements KubeUtils&lt;KubernetesClient&gt; &#123; private KubernetesClient client; private static final int CONNECTION_TIMEOUT = 3 * 1000; private static final int REQUEST_TIMEOUT = 3 * 1000; private static Logger logger = Logger.getLogger(Fabric8KubeUtils.class); @Override public KubernetesClient getClient() &#123; return client; &#125; @Override public void setClient(KubernetesClient client) &#123; this.client = client; &#125; private Fabric8KubeUtils(KubernetesClient client) &#123; this.client = client; &#125; /**传入参数，连接k8s的api server**/ public static KubeUtils buildKubeUtils(Cluster cluster, String namespace) throws K8sDriverException &#123; if (cluster == null) &#123; throw new K8sDriverException(&quot;cluster is null&quot;); &#125; String key = cluster.md5Key(namespace); if (KUBEUTILSMAP.containsKey(key)) &#123; return KUBEUTILSMAP.get(key); &#125; String master = cluster.getApi(); master = CommonUtil.fullUrl(master); if (StringUtils.isBlank(master)) &#123; throw new K8sDriverException(&quot;master api is null, cluster id=&quot; + cluster.getId() + &quot;, cluster name=&quot; + cluster.getName()); &#125; Config config; if (master.toLowerCase().startsWith(&quot;https://&quot;)) &#123; config = new ConfigBuilder().withMasterUrl(master) .withTrustCerts(true) .withNamespace(namespace) .withOauthToken(cluster.getOauthToken()) .withUsername(cluster.getUsername()) .withPassword(cluster.getPassword()) .removeFromTlsVersions(TlsVersion.TLS_1_0) .removeFromTlsVersions(TlsVersion.TLS_1_1) .removeFromTlsVersions(TlsVersion.TLS_1_2) .withRequestTimeout(REQUEST_TIMEOUT) .withConnectionTimeout(CONNECTION_TIMEOUT) .build(); &#125; else &#123; config = new ConfigBuilder().withMasterUrl(master) .withNamespace(namespace) .withOauthToken(cluster.getOauthToken()) .withUsername(cluster.getUsername()) .withPassword(cluster.getPassword()) .removeFromTlsVersions(TlsVersion.TLS_1_0) .removeFromTlsVersions(TlsVersion.TLS_1_1) .removeFromTlsVersions(TlsVersion.TLS_1_2) .withTrustCerts(true) .withRequestTimeout(REQUEST_TIMEOUT) .withConnectionTimeout(CONNECTION_TIMEOUT) .build(); &#125; KubeUtils kubeUtils = buildKubeUtils(config); KUBEUTILSMAP.putIfAbsent(key, kubeUtils); return kubeUtils; &#125; /**创建client**/ public static KubeUtils buildKubeUtils(Config config) throws K8sDriverException &#123; KubernetesClient client; try &#123; client = new DefaultKubernetesClient(config); &#125; catch (Exception e) &#123; throw new K8sDriverException(&quot;instantialize kubernetes client error&quot;); &#125; return new Fabric8KubeUtils(client); &#125; &#125; 4.3 创建k8s的资源对象，作为参传给client操作k8s（增删改时需要）123// 可以通过k8s??Builder()来创建资源对象// 如下创建一个service对象，lb为包含service必要信息的实体类对象Service newService = new K8sServiceBuilder(lb).build(); 4.4 通过得到的client，可以对k8s的各种资源增删改查各种操作：NodesNamespacesServicesReplicationcontrollersPodsDeploymentsResourcequotas1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/**创建pod**/@Override public Pod createPod(Pod pod) throws K8sDriverException &#123; logger.debug(&quot;create pod with specify=&quot; + pod.toString()); try &#123; return client.pods().create(pod); &#125; catch (KubernetesClientException e) &#123; throw new K8sDriverException(e.getMessage()); &#125; &#125;/**创建service**/@Overridepublic Service createService(Service service) throws K8sDriverException &#123; logger.debug(&quot;create service=&quot; + service); if (service == null) &#123; return null; &#125; try &#123; return client.services().create(service); &#125; catch (KubernetesClientException e) &#123; throw new K8sDriverException(e.getMessage()); &#125;&#125;/**创建RC**/ @Override public ReplicationController createReplicationController(ReplicationController rc) throws K8sDriverException &#123; if (rc == null) &#123; return null; &#125; logger.debug(&quot;create replication controller with rc=\\n&quot; + rc); try &#123; return client.replicationControllers().create(rc); &#125; catch (KubernetesClientException e) &#123; throw new K8sDriverException(e.getMessage()); &#125; &#125;/**创建deployment**/@Override public Deployment createDeployment(Deployment deployment) throws K8sDriverException &#123; if (deployment == null) &#123; return null; &#125; logger.debug(&quot;create deployment with deployment=\\n&quot; + deployment); try &#123; return client.extensions().deployments().create(deployment); &#125; catch (KubernetesClientException e) &#123; throw new K8sDriverException(e.getMessage()); &#125; &#125;/**按条件列出所有node**/@Override public NodeList listNode(Map&lt;String, String&gt; labelSelector) throws K8sDriverException &#123; logger.debug(&quot;list node with selector=&quot; + labelSelector); try &#123; return client.nodes().withLabels(labelSelector).list(); &#125; catch (KubernetesClientException e) &#123; throw new K8sDriverException(e.getMessage()); &#125; &#125;","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"kuberbets","slug":"kuberbets","permalink":"http://yoursite.com/tags/kuberbets/"}]},{"title":"用python 分析微信好友信息并生成词云","slug":"用python 分析微信好友信息并生成词云","date":"2017-08-07T01:24:33.000Z","updated":"2017-08-07T01:50:17.806Z","comments":true,"path":"2017/08/07/用python 分析微信好友信息并生成词云/","link":"","permalink":"http://yoursite.com/2017/08/07/用python 分析微信好友信息并生成词云/","excerpt":"","text":"在知乎上偶然看到有人推荐itchart这个微信接口，抱着好奇的想法尝试了以下，果然非常好玩。官方链接：http://itchat.readthedocs.io/zh/latest/#itchat 目录结构get_info.py这个类用来爬取好友信息并保存到指定文件12345678910111213141516171819202122232425import itchatimport osimport timebasepath = os.path.dirname(os.path.realpath(__file__))download_path = basepath+&apos;\\downloads&apos;+ &apos;\\\\&apos;# 调用itchat接口登录并拉取数据itchat.login()friends = itchat.get_friends(update=True)[0:]fmt=&apos;%Y%m%d%H%M%S&apos; #定义时间显示格式Date=time.strftime(fmt,time.localtime(time.time()))download_file_name = &apos;friendslist_&apos;+friends[0][&apos;NickName&apos;]+ &apos;_&apos; + Date + &apos;.txt&apos;f = open(download_path+download_file_name,&apos;wb&apos;)print(download_path+download_file_name)for i in friends[1:]: friend = (str(i) + &quot;\\n&quot;).encode(encoding=&apos;gb18030&apos;) # print(str(i)) f.write(friend)f.close() analyse.py这个类根据下载的好友数据分析好友信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# Author:Jason.wangimport reimport osimport timebase_pic = &quot;C:/Users/Think/Pictures/Saved Pictures/beb28c538ac52a91.jpg&quot;source_file = &quot;friendslist_雨佳Clara_20170724223344.txt&quot;source_file = &quot;friendslist_say_20170724132202.txt&quot;basepath = os.path.dirname(os.path.realpath(__file__))download_file = basepath+&apos;\\downloads\\\\&apos;+ source_filefs_str = &apos;&apos;with open(download_file,&apos;rb&apos;) as f: fs_str = f.read().decode(&apos;gb18030&apos;)friends = fs_str.split(&apos;\\n&apos;)# 初始化计数器 male = female = other = 0# 所有省份Provinces_list = []#friends[0]是自己的信息，所以要从friends[1]开始 for i in friends: if i.__len__()&gt;0: i = i.replace(&apos;&lt;ContactList: [&apos;,&apos;&quot;&lt;ContactList: [&apos;) i = i.replace(&apos;]&gt;&apos;,&apos;]&gt;&quot;&apos;) friend = eval(i) # 统计性别 sex = friend[&quot;Sex&quot;] if sex == 1: male += 1 exit elif sex ==2: female += 1 else: other+=1 # 统计地区 Province = friend[&quot;Province&quot;] Provinces_list.append(Province)#计算朋友总数 total = len(friends)#打印出自己的好友性别比例 print(&quot;总好友数： %d&quot; % total + &quot;\\n&quot; + &quot;男性好友： %d 个,占比 %.2f%%&quot; % (male,(float(male)/total*100)) + &quot;\\n&quot; + &quot;女性好友： %d 个,占比 %.2f%%&quot; % (female,(float(female) / total * 100)) + &quot;\\n&quot; + &quot;不明性别好友： %d 个,占比 %.2f%%&quot; % (other,(float(other) / total * 100)))Provinces_set = set(Provinces_list)Provinces_dict = &#123;&#125;for i in Provinces_set: Provinces_dict[i] = Provinces_list.count(i)# 对省份字典按value排序Provinces_dict = sorted(Provinces_dict.items(),key=lambda asd:asd[1],reverse=True)print(&quot;===============人数排名前10地区如下==================&quot;)top = 0for k,v in Provinces_dict: if top&lt;10: print(&quot;%s : %d 个，占比 ： %.2f%%&quot; % (k,v,float(v)/total*100)) top+=1 输出结果： ciyun.py根据签名生成词云123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# -*- coding:UTF-8 -*-# Author:Jason.wangimport reimport osimport timebase_pic = &quot;C:/Users/Think/Pictures/Saved Pictures/beb28c538ac52a91.jpg&quot;source_file = &quot;friendslist_雨佳Clara_20170724223344.txt&quot;# source_file = &quot;friendslist_say_20170724132202.txt&quot;basepath = os.path.dirname(os.path.realpath(__file__))download_file = basepath+&apos;\\downloads\\\\&apos;+ source_filefs_str = &apos;&apos;with open(download_file,&apos;rb&apos;) as f: fs_str = f.read().decode(&apos;gb18030&apos;)friends = fs_str.split(&apos;\\n&apos;)siglist = []for i in friends: if i.__len__()&gt;0: i = i.replace(&apos;&lt;ContactList: [&apos;,&apos;&quot;&lt;ContactList: [&apos;) i = i.replace(&apos;]&gt;&apos;,&apos;]&gt;&quot;&apos;) friend = eval(i) # print(friend) # print(friend[&quot;Signature&quot;]) signature = friend[&quot;Signature&quot;].strip().replace(&quot;span&quot;,&quot;&quot;).replace(&quot;class&quot;,&quot;&quot;).replace(&quot;emoji&quot;,&quot;&quot;) rep = re.compile(&quot;1f\\d+\\w*|[&lt;&gt;/=]&quot;) signature = rep.sub(&quot;&quot;,signature) siglist.append(signature)text = &quot;&quot;.join(siglist)import jiebawordlist = jieba.cut(text,cut_all=True)word_space_split = &quot; &quot;.join(wordlist).replace(&quot;\\n&quot;,&quot;&quot;)print(word_space_split)import matplotlib.pyplot as pltfrom wordcloud import WordCloud, ImageColorGeneratorimport numpy as npimport PIL.Image as Imagecoloring = np.array(Image.open(base_pic))my_wordcloud = WordCloud(background_color=&quot;white&quot;,max_words=2000, mask=coloring,max_font_size=60,random_state=42,scale=2, font_path=&quot;C:/windows/fonts/SimHei.ttf&quot;).generate(word_space_split)image_colors = ImageColorGenerator(coloring)plt.imshow(my_wordcloud.recolor(color_func=image_colors))plt.imshow(my_wordcloud)plt.axis(&quot;off&quot;)plt.show() 效果：","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"微信","slug":"微信","permalink":"http://yoursite.com/tags/微信/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"flask 应用的架构和部署(flask+gunicorn+nginx)","slug":"flask 应用的架构和部署(flask+gunicorn+nginx)","date":"2017-07-07T01:44:33.000Z","updated":"2017-08-08T06:38:51.099Z","comments":true,"path":"2017/07/07/flask 应用的架构和部署(flask+gunicorn+nginx)/","link":"","permalink":"http://yoursite.com/2017/07/07/flask 应用的架构和部署(flask+gunicorn+nginx)/","excerpt":"","text":"本文主要介绍flask+gunicorn+nginx的配合部署过程，它只是入门的部署过程，当你的web应用有并发要求时，还应加上缓存和队列调度等等，这部分可以参考https://zhuanlan.zhihu.com/p/25038203 前言： 1.为什么要使用gunicorn？目前我们使用flask内建的wsgi server，这个server由于是单进程单线程模型的，所以性能很差，一个请求不处理完的话服务器就会阻塞住其他请求，我们需要对这个server做替换。而gunicorn是一个python编写的高效的WSGI HTTP服务器，它比uwsgi使用更简单2.为什么需要nginx？nginx反向代理能带给我们很多好处： 负载均衡，把请求平均地分到上游的app server进程。 静态文件处理，静态文件的访问交给nginx来处理，降低了app server的压力。 接收完客户端所有的TCP包，再一次交给上游的应用来处理，防止app server被慢请求干扰。 访问控制和路由重写。 强大的ngx_lua模块。 Proxy cache。 Gzip，SSL… 应用架构: 部署步骤： 1. wsgi项目中创建wsgi.py1234from app import create_appapplication = create_app(&apos;production&apos;)if __name__ == &apos;__main__&apos;: application.run() 2.远程复制scp远程复制项目文件到服务器12# 在本地目录内执行scp -r app jason@10.222.32.10:/usr/share/www 3.安装各种环境和依赖包并测试gunicorn服务在服务器上执行12345678910111213# 安装venv环境virtualenv venv. venv/bin/activate# 安装依赖包pip install -r requirements.txt#安装gunicornpip install gunicorn# 测试运行服务gunicorn -w 4 -b 127.0.0.1:8000 wsgi:application# 解释-w ：要开多少个worker，即开启几个进程-b ：指定host地址wsgi: ：声明入口wsgi文件中的全局变量 4.配置upstart在linux启动时就跟随启动起来在项目中编写upstart.conf并复制到服务器命名为blog.conf12345678910111213description &quot;My Blog service&quot;# 运行级别start on runlevel [2345]stop on runlevel [!2345]# 用户id和用户组respawnsetuid rootsetgid www-data# 运行路径和服务运行时的工作目录env PATH=/usr/share/www/venv/binchdir /usr/share/www/exec gunicorn -w 4 -b 127.0.0.1:8000 wsgi:application 在服务器端123456# 建立服务目录配置sudo nano /etc/init/blog.conf# 测试建立的文件deactivate# 开启服务sudo service blog start 5. 配置nginx（反向代理）在项目中编写nginx.conf12345678910111213# /ect/nginx/sites-available/defaultserver &#123; listen 80; server_name 10.211.55.10; location / &#123; # 要和gunicorn配置的host地址对应上 proxy_pass http://127.0.0.1:8000; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 在服务器端12345# 进入nginx默认配置文件sudo nano /ect/nginx/sites-available/default# 将server&#123;&#125;中的内容替换为上面写的内容# 重启nginxsudo service nginx restart 6. 初始化数据库并重启服务在服务器端12345678createdb blog-dbcd /usr/share/www. venv/bin/activatepython manage.py db upgradedeactivatesudo service blog restart","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"kuberbets","slug":"kuberbets","permalink":"http://yoursite.com/tags/kuberbets/"}]},{"title":"如何运用docker配合python开发","slug":"如何运用docker配合python开发","date":"2017-07-05T01:44:33.000Z","updated":"2017-08-09T02:15:57.545Z","comments":true,"path":"2017/07/05/如何运用docker配合python开发/","link":"","permalink":"http://yoursite.com/2017/07/05/如何运用docker配合python开发/","excerpt":"","text":"由于开发一个python程序时需要依赖大量的三方库包，且python2和3本身就有互不兼容的地方，我们往往需要一个隔离的环境，来避免版本影响造成的bug。传统的做法大多数人可能会选择virtualenv来隔离，但是它有很多明显的缺点： 无法提供完全的隔离 如果不想在正式环境中使用，它就会造成差异 而随着容器技术的日渐成熟和普及，Docker无疑成为解决这个问题的最优解本文将主要介绍docker和flask的配合开发 步骤：1.安装Docker（这里不详细介绍）12# 参考命令sudo wget -qO- https://get.docker.com/ | sh 2.应用目录结构123456789├──fanxiangce_docker ├── Dockerfile ├── Readme.md └─fanxiangce └──app ├── manage.py └── requirements ├── common.txt 3.编写Dockerfile（详细命令解释可以参考https://docs.docker.com/engine/reference/builder/#environment-replacement）12345678910111213141516171819202122232425262728293031323334353637383940########################################################## # Dockerfile to run a flask-based web application# Based on an centos:7 image ########################################################### Set the base image to use to centos FROM centos:7# Set the file maintainer MAINTAINER jasonwang,wjs7740@163.com# Set env varibles used in this Dockerfile (add a unique prefix, such as DOCKYARD) # Local directory with project source ENV DOCKYARD_SRC=fanxiangce# Directory in Container for all project files ENV DOCKYARD_SRCHOME=/opt # Directory in container for project source files ENV DOCKYARD_SRCPROJ=/opt/fanxiangce# Update the defualt application repository source list RUN yum -y install epel-release RUN yum -y install python-pip RUN yum clean all# Copy application source code to SRCDIR COPY $DOCKYARD_SRC $DOCKYARD_SRCPROJ# Create application subdirectories WORKDIR $DOCKYARD_SRCPROJ RUN mkdir log VOLUME [&apos;$DOCKYARD_SRCPROJ/log/&apos;]# Install Python dependencies RUN pip install --upgrade pipRUN pip install -r $DOCKYARD_SRCPROJ/requirements/common.txt# Port to expose EXPOSE 8000# Copy entrypoint script into the image WORKDIR $DOCKYARD_SRCPROJ 4. build镜像12# 在Dockerfile同级目录下sudo docker build -t jason/webdemo . 成功后显示Successfully，同时返回镜像ID，如图： 5.查看并启动镜像注意，此处-p映射的端口（主机端口：容器端口），容器端口应与flask应用定义的端口一致12sudo docker imagessudo docker run -it --name webdemo -p 8000:8000 jason/webdemo /bin/bash 6.在容器中启动flask应用1python manage.py runserver -p 8000 启动成功如下截图： 7.在浏览器输入127.0.0.1:8000即可访问应用 8.后续如果容器关闭后需要再次进入，可以用如下命令123456# 查看当前容器 sudo docker ps -a# 启动容器docker start webdemo# 进入容器docker attach webdemo","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"kuberbets","slug":"kuberbets","permalink":"http://yoursite.com/tags/kuberbets/"}]},{"title":"java实现将多个文件打包成zip压缩文件以及对压缩文件的加密","slug":"java实现将多个文件打包成zip压缩文件以及对压缩文件的加密 - 副本","date":"2016-01-05T01:44:33.000Z","updated":"2017-08-09T02:19:53.913Z","comments":true,"path":"2016/01/05/java实现将多个文件打包成zip压缩文件以及对压缩文件的加密 - 副本/","link":"","permalink":"http://yoursite.com/2016/01/05/java实现将多个文件打包成zip压缩文件以及对压缩文件的加密 - 副本/","excerpt":"","text":"如果仅仅需要对文件进行压缩，方法比较简单，因为java的util包中提供了相关的压缩方法.首先，引入java.util.zip.ZipEntry,java.util.zip.ZipOutputStream包然后加入以下代码：1234567891011121314151617181920String now = StringUtils.dateToString(new Date());String path = request.getServletPath();path = request.getRealPath(path);path = path.substring(0,path.lastIndexOf(&quot;\\\\&quot;))+&quot;\\\\&quot;;File zipFile = new File(path+&quot;edm_expcsv\\\\&quot;+&quot;EDM_expcsv_&quot;+now+&quot;.zip&quot;); //压缩的文件名和地址 ZipOutputStream out2 = new ZipOutputStream(new FileOutputStream(zipFile));//传入压缩文件路径，得到压缩流 byte[] buffer = new byte[1024]; File[] file1 = &#123;new File(path+file),new File(path+file2)&#125;;for(int x=0;x&lt;file1.length;x++) &#123; FileInputStream fis = new FileInputStream(file1[x]);out2.putNextEntry(new ZipEntry(file1[x].getName()));//将要压缩的文件放入压缩流 int len;//读入需要下载的文件的内容，打包到zip文件 while((len = fis.read(buffer))&gt;0) &#123; out2.write(buffer,0,len); &#125; out2.closeEntry(); fis.close();&#125;out2.close(); 如果是要对文件压缩并加密，则使用下面的方法，但是值支持单个文件压缩 先将ant.jar commons-io.jar EncryptZip.jar EncryptZip.jar winzip.1.1.0.jar文件放到lib包中 然后在头文件import中加入String,java.io.File,de.idyl.winzipaes.AesZipFileEncrypter,de.idyl.winzipaes.impl.AESEncrypterBC 然后加入代码1234567File file = newFile(s); //定义压缩文件的路径File zipFile = new File(b + &quot;\\\\demo.zip&quot;);//压缩的文件名和地址AESEncrypterBC bc = new AESEncrypterBC();AesZipFileEncrypter azfe = new AesZipFileEncrypter(zipFile, bc);azfe.setEncoding(&quot;UTF-8&quot;); // 编码格式是在这传进去的azfe.add(file,&quot;123.jpg&quot;, &quot;123&quot;); //1：要压缩的文件路径，2：为压缩的文件命名3：为密码azfe.close();","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]}]}